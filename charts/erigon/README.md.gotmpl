{{ template "graphops.title" . }}

{{ template "chart.description" . }}

{{ template "graphops.badges" . }}

## Features

- Actively maintained by [GraphOps](https://graphops.xyz) and contributors
- Supports deploying a `rpcdaemon` sidecar within the `Pod` that contains the stateful `erigon` container, allowing direct database access and higher performance for the sidecar `rpcdaemon`
- Supports an independent pool of `rpcdaemon` instances, with auto-scaling support, for automatic elastic JSON-RPC
- Strong security defaults (non-root execution, ready-only root filesystem, drops all capabilities)
- Readiness checks to ensure traffic only hits `Pod`s that are healthy and ready to serve requests
- Support for `PodMonitor`s to configure Prometheus to scrape metrics ([kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack))
- Support for configuring Grafana dashboards for Erigon ([kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack))

## Todo

- Support for installing [grafana-operator](https://github.com/grafana-operator/grafana-operator) `Dashboard`s
- Figure out release notes automation https://github.com/helm/helm/blob/main/scripts/release-notes.sh
- Move ulimit config to separate chart
- Test removing chmod initContainer given that we gave fsGroup
- Make another pass on values.yaml and annotate with docs
- https://github.com/grafana/helm-charts/blob/main/charts/grafana/templates/servicemonitor.yaml

## Quickstart

To install the chart with the release name `my-release`:

```console
$ helm repo add graphops http://graphops.github.io/charts
$ helm install my-release graphops/{{ template "chart.name" . }}
```

## JSON-RPC

### High-performance sidecar

You can enable the deployment of an `rpcdaemon` instance as a sidecar within the stateful Erigon `Pod`. In this mode, the `rpcdaemon` shares a PID namespace with the `erigon` process and can access the node database directly, cutting out the gRPC API and improving synchronous request performance.

When enabled, you can access the JSON-RPC API via the stateful node `Service` on port `8545` by default. See the Values section to configure the sidecar.

### Scalable `Deployment`

For workloads where synchronous performance is less important than the scalability of request throughput, you can enable an independent scalable `Deployment` of `rpcdaemon`s. In this mode, the `rpcdaemon`s can be scaled up arbitrarily and connect to the stateful node process via the gRPC API. You can also use node selectors and other placement configuration to customise where `rpcdaemon`s are deployed within your cluster.

When enabled, a dedicated `Service` will be created to access JSON-RPC via the scalable `Deployment`.

#### Autoscaling

You can enable autoscaling for the scalable `Deployment` of `rpcdaemon`s. When enabled, the Chart will install a Horizontal Pod Autoscaler into the cluster, which will manage the number of `rpcdaemon` replicas based on resource utilization.

If doing this, be sure to configure `rpcdaemons.resources.requests` with appropriate values, as the CPU and Memory utilization targets set in the autoscaling config are relative to the requested resource values.

{{ template "chart.requirementsSection" . }}

{{ template "chart.valuesSection" . }}

## See also

host-ulimit-config, dshackle

{{ template "graphops.contributingSection" . }}
